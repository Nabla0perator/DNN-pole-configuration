{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Module for teaching dataset generation\n",
    "This module contains the important parameters needed in the generation of teaching dataset. The important part of this module is the class `pole` which creates an object that contains the pole position, Riemann sheet location, provides sshadow pole information and a method `pole.smat` that gives the pole's S-matrix contribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17977600"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4*2120*2120 #(17977600) #35*720*720 #(18144000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cmath as cm\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import chainer\n",
    "from chainer import configuration\n",
    "from chainer.dataset import convert\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the global parameters used in generating the dataset. This includes the hadron masses and the center-of-mass energy $E_{cm}$ where the cross-section is to be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#Units in MeV\n",
    "Nucleon = 938.9186795\n",
    "Pion = 138.0394\n",
    "Eta  = 547.862 \n",
    "\n",
    "mu_NN   = 1/(1/Nucleon + 1/Nucleon)\n",
    "mu_piN  = 1/(1/Pion + 1/Nucleon)\n",
    "mu_etaN = 1/(1/Eta + 1/Nucleon)\n",
    "\n",
    "T_piN  = Nucleon + Pion\n",
    "T_etaN = Nucleon + Eta\n",
    "T_KLam = 1611.42\n",
    "T_KSig = 1688.32\n",
    "\n",
    "#choose system by specifying reduced mass (convert to fm^-1)\n",
    "mu1 = mu_piN/(197.3)\n",
    "mu2 = mu_etaN/(197.3)\n",
    "\n",
    "T1 = T_piN/(197.3)\n",
    "T2 = T_etaN/(197.3)\n",
    "T3 = T_KLam/(197.3)\n",
    "T4 = T_KSig/(197.3)\n",
    "\n",
    "#Number of real and imaginary parts of the pole\n",
    "#Choose even numbers only\n",
    "Nreal = 2120\n",
    "Nimag = 2120\n",
    "\n",
    "#Generate Npole poles within the counting region\n",
    "#units in MeV\n",
    "Erealbelow = np.random.uniform(low=T_etaN-50, high=T_etaN, size=int(Nreal/2))\n",
    "Erealabove = np.random.uniform(low=T_etaN, high=T_KSig, size=int(Nreal/2))\n",
    "Ereal = np.concatenate((Erealbelow, Erealabove))\n",
    "Eimag = np.random.uniform(low=0.0, high=200.0, size=Nimag)\n",
    "    \n",
    "#Generate poles beyond the counting region\n",
    "#units in MeV\n",
    "Erealbelow = np.random.uniform(low=T_piN-2000, high=T_piN-100, size=int(Nreal/2))\n",
    "Erealabove = np.random.uniform(low=T_etaN+500, high=T_KSig+5000, size=int(Nreal/2))\n",
    "Erealfar = np.concatenate((Erealbelow, Erealabove))\n",
    "Eimagfar = np.random.uniform(low=700.0, high=2000.0, size=Nimag)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect = True\n",
    "inspect = False\n",
    "directory = 'curriculum01_training'\n",
    "#curr01 datasets: 00, 01, 11, 21\n",
    "\n",
    "#directory = 'curriculum02_training'\n",
    "#curr02 datasets: 00, 01, 11, 21, 02\n",
    "#directory = 'curriculum03_training'\n",
    "#curr03 datasets: 00, 01, 11, 21, 02, 12\n",
    "#directory = 'curriculum04_training'\n",
    "#curr04 datasets: 00, 01, 11, 21, 02, 12, 22\n",
    "#directory = 'curriculum05_training'\n",
    "#curr05 datasets: 00, 01, 11, 21, 02, 12, 22, 10\n",
    "#directory = 'curriculum06_training'\n",
    "#curr06 datasets: 00, 01, 11, 21, 02, 12, 22, 10, 20\n",
    "#directory = 'curriculum07_training'\n",
    "#curr07 datasets: 00, 01, 11, 21, 02, 12, 22, 10, 20, 30\n",
    "\n",
    "\n",
    "#directory = 'curriculum08_training'\n",
    "#curr08 datasets: 00, 01, 11, 21, 02, 12, 22, 10, 20, 30, 03\n",
    "\n",
    "#directory = 'curriculum32_training'\n",
    "#all datasets\n",
    "\n",
    "\n",
    "#directory = 'sample_plot'\n",
    "\n",
    "if not os.path.isdir(directory):\n",
    "    os.makedirs(directory)\n",
    "print('Number of poles to be generated per class:', Nreal*Nimag)\n",
    "print('Ndata to be generated=', 4*Nreal*Nimag)\n",
    "print('Your directory is:', directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the output label for DNN RS pole-counter (maximum of 4 poles only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive labels of network output\n",
    "#at most 4 poles in all RS\n",
    "labelz = [\n",
    "#default no pole\n",
    "    'no nearby pole',                          #00\n",
    "#poles in [bt]    \n",
    "    '1 pole  in [bt]',                          #01\n",
    "    '2 poles in [bt]',                         #02\n",
    "    '3 poles in [bt]',                         #03\n",
    "    '4 poles in [bt]',                         #04\n",
    "#[bt] and [bb] no shadow pair    \n",
    "    '3 poles in [bt] and 1 pole  in [bb]',      #05\n",
    "    '2 poles in [bt] and 1 pole  in [bb]',      #06\n",
    "    '2 poles in [bt] and 2 poles in [bb]',     #07 \n",
    "    '1 pole  in [bt] and 2 poles in [bb]',      #08\n",
    "    '1 pole  in [bt] and 3 poles in [bb]',     #09\n",
    "    '1 pole  in [bt] and 1 pole  in [bb]',      #10\n",
    "#poles in [bb] only    \n",
    "    '1 pole  in [bb]',                          #11\n",
    "    '2 poles in [bb]',                         #12\n",
    "    '3 poles in [bb]',                         #13\n",
    "    '4 poles in [bb]',                         #14\n",
    "#[bb] and [tb] no shadow pair    \n",
    "    '3 poles in [bb] and 1 pole  in [tb]',      #15\n",
    "    '2 poles in [bb] and 1 pole  in [tb]',      #16\n",
    "    '2 poles in [bb] and 2 poles in [tb]',     #17   \n",
    "    '1 pole  in [bb] and 2 poles in [tb]',      #18\n",
    "    '1 pole  in [bb] and 3 poles in [tb]',     #19\n",
    "    '1 pole  in [bb] and 1 pole  in [tb]',      #20\n",
    "#poles in [tb] only    \n",
    "    '1 pole  in [tb]',                          #21\n",
    "    '2 poles in [tb]',                         #22\n",
    "    '3 poles in [tb]',                         #23\n",
    "    '4 poles in [tb]',                         #24    \n",
    "#[tb] and [bt]\n",
    "    '3 poles in [tb] and 1 pole  in [bt]',      #25\n",
    "    '2 poles in [tb] and 1 pole  in [bt]',      #26\n",
    "    '2 poles in [tb] and 2 poles in [bt]',     #27\n",
    "    '1 pole  in [tb] and 2 poles in [bt]',      #28\n",
    "    '1 pole  in [tb] and 3 poles in [bt]',     #29 \n",
    "    '1 pole  in [tb] and 1 pole  in [bt]',      #30      \n",
    "#poles in all three\n",
    "    '2 poles in [bt] and 1 pole  in [bb] and 1 pole  in [tb]',    #31\n",
    "    '1 pole  in [bt] and 2 poles in [bb] and 1 pole  in [tb]',    #32\n",
    "    '1 pole  in [bt] and 1 pole  in [bb] and 2 poles in [tb]',    #33\n",
    "    '1 pole  in [bt] and 1 pole  in [bb] and 1 pole  in [tb]'      #34\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the energy spacing used in the known PWA of pion-nucleon system such as the <a href=http://gwdac.phys.gwu.edu/analysis/pin_analysis.html>SAID-GWU</a> model, the \n",
    "<a href=http://collaborations.fz-juelich.de/ikp/meson-baryon/juelich_amplitudes.html>Julich-Bonn </a> model and the <a href=https://www.phy.anl.gov/theory/research/anl-osaka-pwa/>ANL-Osaka</a> model. \n",
    "It is preferrable to use the <a href=http://gwdac.phys.gwu.edu/analysis/pin_analysis.html>SAID-GWU</a> mode since it also has uncertainties in the single-energy value solutions. We load the data below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAID-GWU model\n",
    "#Center-of-mass energy axis (in MeV) and the real and imaginary parts of scattering amplitude\n",
    "#Data points not beyond K-Lambda threshold\n",
    "piN_data = pd.read_excel(\"S11-piN.xlsx\", \n",
    "                         sheet_name=\"S11-SAID\", \n",
    "                         usecols=[2,7,9], \n",
    "                         skiprows=[0],\n",
    "                         nrows=37)  #30-upto K-Lambda only\n",
    "E_exp = piN_data[\"Ecm\"].tolist()\n",
    "Treal = piN_data[\"Trl\"].tolist()\n",
    "Timag = piN_data[\"Tim\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that the energy points of the moch data are randomly selected in the desired energy range.\n",
    "#We only use the experimental data to match the number of energy bins.\n",
    "E_exp = np.array(E_exp)\n",
    "Treal = np.array(Treal)\n",
    "Timag = np.array(Timag)\n",
    "Tsqr = np.square(Treal) + np.square(Timag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will be using several assigned poles in the calculation of S-matrix\n",
    "#To simplify the code we introduced the class \"pole\" where the user can \n",
    "#assign the Riemann sheet location and the pole's real and imaginary parts.\n",
    "#The class pole will throw away the resulting shadow pole by choosing \n",
    "#the appropriate ZCL model. Information about the shadow pole can be accessed\n",
    "#by the attribute xxx.shadow\n",
    "#We define a method xxx.smat() to the class pole that gives its contribution to the\n",
    "#overall S-matrix\n",
    "\n",
    "class pole:\n",
    "    def __init__(self, RS, Ereal, Eimag):\n",
    "        #RS is the two-channel Reimann sheet location of the pole\n",
    "        #Use [1,-1] for bt, [-1,-1] for bb and [-1,1] for tb\n",
    "        #Ereal is the real part of energy pole\n",
    "        #Eimag is the imag part of energy pole\n",
    "        Epole = Ereal - (1j)*Eimag\n",
    "        self.pos = Epole\n",
    "        #compute momentum pole\n",
    "        k1pole = cm.sqrt(2.0*mu1*(Epole/197.3-T1))\n",
    "        k2pole = cm.sqrt(2.0*mu2*(Epole/197.3-T2))\n",
    "        alpha1 = np.abs(k1pole.real)\n",
    "        alpha2 = np.abs(k2pole.real)\n",
    "        beta1  = RS[0]*abs(k1pole.imag)\n",
    "        beta2  = RS[1]*abs(k2pole.imag)\n",
    "        \n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        \n",
    "        #coupling for model1: resonance initially coupled to channel 1\n",
    "        lambdaplus_model1 = (-(2.0*mu1*mu2*alpha1**2.0+4.0*mu1**2*beta2**2.0) \\\n",
    "                             +np.sqrt((2.0*mu1*mu2*alpha1**2+4.0*mu1**2.0*beta2**2.0)**2.0 \\\n",
    "                                      -4.0*(mu1*mu2*alpha1**2.0)**2.0))/(2.0*(alpha1*mu2)**2.0)\n",
    "        lambdaminus_model1 = (-(2.0*mu1*mu2*alpha1**2.0+4.0*mu1**2*beta2**2) \\\n",
    "                              -np.sqrt((2*mu1*mu2*alpha1**2+4*mu1**2*beta2**2)**2.0 \\\n",
    "                                       -4.0*(mu1*mu2*alpha1**2.0)**2.0))/(2*(alpha1*mu2)**2.0)\n",
    "        #coupling for model2: resonance initially coupled to channel 2\n",
    "        lambdaplus_model2 = (-(2.0*mu1*mu2*alpha2**2.0+4.0*mu2**2.0*beta1**2.0) \\\n",
    "                             +np.sqrt((2.0*mu1*mu2*alpha2**2.0+4.0*mu2**2.0*beta1**2.0)**2.0 \\\n",
    "                                      -4.0*(mu1*mu2*alpha2**2.0)**2.0))/(2.0*(alpha2*mu1)**2.0)\n",
    "        lambdaminus_model2 = (-(2.0*mu1*mu2*alpha2**2.0+4.0*mu2**2.0*beta1**2.0) \\\n",
    "                              -np.sqrt((2.0*mu1*mu2*alpha2**2.0+4.0*mu2**2.0*beta1**2.0)**2.0 \\\n",
    "                                       -4.0*(mu1*mu2*alpha2**2.0)**2.0))/(2*(alpha2*mu1)**2.0)        \n",
    "        \n",
    "        #the choice of model depends on the assigned Riemann sheet\n",
    "        if RS==[-1,1]:  #[bt] or second Riemann sheet\n",
    "            #use initially-coupled to channel 1 model\n",
    "            model = 1\n",
    "            lambdaplus = lambdaplus_model1\n",
    "            lambdaminus = lambdaminus_model1\n",
    "        elif RS==[1,-1] or RS==[-1,-1]:  #[tb] or fourth Riemann sheet/ [bb] or third Riemann sheet\n",
    "            #use initially-coupled to channel 2 model\n",
    "            model = 2\n",
    "            lambdaplus = lambdaplus_model2\n",
    "            lambdaminus = lambdaminus_model2\n",
    "        #Note on [bb]: It is safe to use model 2 for [bb] since the shadow is guaranteed to be in [tb],\n",
    "        #and is always below the assigned pole. This makes the shadow irrelevant in the second threshold region\n",
    "             \n",
    "        \n",
    "        #Check if the pole is relevant\n",
    "        if Eimag>500:\n",
    "            #if pole is background, use weak coupling\n",
    "            #shadow pole here will also be irrelevant\n",
    "            lambdacoup = np.random.uniform(low=0.5*lambdaplus, high=-0.5*lambdaplus) \n",
    "        elif Eimag<500:\n",
    "            #if poles is relevant, use strong coupling to\n",
    "            #throw shadow poles\n",
    "            lambdacoup = np.random.uniform(low=0.5*(lambdaminus-lambdaplus)+lambdaplus, high=0.99*lambdaplus)\n",
    "            if Eimag<10:\n",
    "                lambdacoup = np.random.uniform(low=lambdaminus, high=lambdaplus)\n",
    "        #the official coupling:\n",
    "        self.lambdacoup = lambdacoup\n",
    "        #Let us calculate the shadow pole\n",
    "        if model == 1:\n",
    "            shadowp1 = (1j)*beta1*((mu1-mu2*lambdacoup)/(mu1+mu2*lambdacoup))+cm.sqrt(alpha1**2.0+4.0*lambdacoup*mu1**2.0*beta2**2.0/(mu1+mu2*lambdacoup)**2.0)\n",
    "            shadowp2 = (1j)*beta2*(-(mu1-mu2*lambdacoup)/(mu1+mu2*lambdacoup))+cm.sqrt(alpha2**2.0+4.0*lambdacoup*mu2**2.0*beta1**2.0/(mu1+mu2*lambdacoup)**2.0)\n",
    "            shadowm1 = (1j)*beta1*((mu1-mu2*lambdacoup)/(mu1+mu2*lambdacoup))-cm.sqrt(alpha1**2.0+4.0*lambdacoup*mu1**2.0*beta2**2.0/(mu1+mu2*lambdacoup)**2.0)\n",
    "            shadowm2 = (1j)*beta2*(-(mu1-mu2*lambdacoup)/(mu1+mu2*lambdacoup))-cm.sqrt(alpha2**2.0+4.0*lambdacoup*mu2**2.0*beta1**2.0/(mu1+mu2*lambdacoup)**2.0)\n",
    "        elif model == 2:\n",
    "            shadowp1 = (1j)*beta1*((mu1*lambdacoup-mu2)/(mu1*lambdacoup+mu2))+cm.sqrt(alpha1**2.0+4.0*lambdacoup*mu1**2.0*beta2**2.0/(mu1*lambdacoup+mu2)**2.0)\n",
    "            shadowp2 = (1j)*beta2*(-(mu1*lambdacoup-mu2)/(mu1*lambdacoup+mu2))+cm.sqrt(alpha2**2.0+4.0*lambdacoup*mu2**2.0*beta1**2.0/(mu1*lambdacoup+mu2)**2.0)\n",
    "            shadowm1 = (1j)*beta1*((mu1*lambdacoup-mu2)/(mu1*lambdacoup+mu2))-cm.sqrt(alpha1**2.0+4.0*lambdacoup*mu1**2.0*beta2**2.0/(mu1*lambdacoup+mu2)**2.0)\n",
    "            shadowm2 = (1j)*beta2*(-(mu1*lambdacoup-mu2)/(mu1*lambdacoup+mu2))-cm.sqrt(alpha2**2.0+4.0*lambdacoup*mu2**2.0*beta1**2.0/(mu1*lambdacoup+mu2)**2.0)\n",
    "        \n",
    "        #Riemann sheet identifier for shadow pole\n",
    "        def RSlabel(pimag1, pimag2):\n",
    "            if pimag1>0 and pimag2>0:\n",
    "                RS = 'tt'\n",
    "            elif pimag1<0 and pimag2>0:\n",
    "                RS = 'bt'\n",
    "            elif pimag1<0 and pimag2<0:\n",
    "                RS = 'bb'\n",
    "            elif pimag1>0 and pimag2<0:\n",
    "                RS = 'tb'\n",
    "            return RS\n",
    "        #Attributes for the shadow pole (for inspection purposes only)\n",
    "        #This will give the energy shadow pole in MeV with its RS location\n",
    "        self.shadow = ['{:.2f}'.format((shadowp1**2.0/(2.0*mu1)+T1)*197.3), RSlabel(shadowp1.imag, shadowp2.imag),  \n",
    "                       '{:.2f}'.format((shadowm1**2.0/(2.0*mu1)+T1)*197.3), RSlabel(shadowm1.imag, shadowm2.imag)]\n",
    "        #Riemann sheet of the pole\n",
    "        self.RS = RSlabel(beta1, beta2)\n",
    "        #The model used for this pole (needed in the method part)\n",
    "        self.model = model\n",
    "    def smat(self,p1,p2):\n",
    "        #this is the method to compute S-matrix contribution of the pole\n",
    "        #all parameters must be defined as attribute (self)\n",
    "        if self.model == 1:\n",
    "            Dnum = ((-p1-(1j)*self.beta1)**2.0 - self.alpha1**2.0)+self.lambdacoup*((p2-(1j)*self.beta2)**2.0 - self.alpha2**2.0)\n",
    "            Dden = ((p1-(1j)*self.beta1)**2.0 - self.alpha1**2.0)+self.lambdacoup*((p2-(1j)*self.beta2)**2.0 - self.alpha2**2.0)\n",
    "        elif self.model == 2:\n",
    "            Dnum = self.lambdacoup*((-p1-(1j)*self.beta1)**2.0 - self.alpha1**2.0)+((p2-(1j)*self.beta2)**2.0 - self.alpha2**2.0)\n",
    "            Dden = self.lambdacoup*((p1-(1j)*self.beta1)**2.0 - self.alpha1**2.0)+((p2-(1j)*self.beta2)**2.0 - self.alpha2**2.0)\n",
    "        smatcontribution = Dnum/Dden    \n",
    "        return (smatcontribution)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipduplicate(real1, imag1, Nreal, Nimag):\n",
    "    #This is to avoid possible duplication of poles in the same Riemann sheet\n",
    "    real_list = list(range(1,Nreal))\n",
    "    imag_list = list(range(1,Nimag))\n",
    "    real2 = np.random.choice([entry for entry in real_list if entry != real1]) \n",
    "    real3 = np.random.choice([entry for entry in real_list if entry != real1 and entry != real2])\n",
    "    real4 = np.random.choice([entry for entry in real_list if entry != real1 and entry != real2 and entry != real3])\n",
    "    real5 = np.random.choice([entry for entry in real_list if entry != real1 and entry != real2 and entry != real3 and entry != real4])\n",
    "    real6 = np.random.choice([entry for entry in real_list if entry != real1 and entry != real2 and entry != real3 and entry != real4 and entry != real5])\n",
    "    imag2 = np.random.choice([entry for entry in imag_list if entry != imag1])\n",
    "    imag3 = np.random.choice([entry for entry in imag_list if entry != imag1 and entry != imag2])\n",
    "    imag4 = np.random.choice([entry for entry in imag_list if entry != imag1 and entry != imag2 and entry != imag3])\n",
    "    imag5 = np.random.choice([entry for entry in imag_list if entry != imag1 and entry != imag2 and entry != imag3 and entry != imag4])\n",
    "    imag6 = np.random.choice([entry for entry in imag_list if entry != imag1 and entry != imag2 and entry != imag3 and entry != imag4 and entry != imag5])\n",
    "    indx = [[real1, real2, real3, real4, real5, real6],[imag1, imag2, imag3, imag4, imag5, imag6]]\n",
    "    return indx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seerealimagpart(Einput, ReT11, ImT11,labelout, data_info):\n",
    "    #chckind is a random integer to call one of the generated data sample\n",
    "    chckind = np.random.randint(0,len(labelout))\n",
    "    font_set_size = 15\n",
    "    Thres1, ValatThres1 = [T_piN, T_piN], [-max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind]))), max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind])))]\n",
    "    Thres2, ValatThres2 = [T_etaN, T_etaN], [-max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind]))), max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind])))]\n",
    "    Thres3, ValatThres3 = [T_KLam, T_KLam], [-max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind]))), max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind])))]\n",
    "    Thres4, ValatThres4 = [T_KSig, T_KSig], [-max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind]))), max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind])))]\n",
    "    Horx, Hory = [T_piN, T_KSig], [0, 0]\n",
    "    plt.ylim(-max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind])))-0.05,max(max(ReT11[chckind]**2.0+ImT11[chckind]**2.0),max(np.abs(ReT11[chckind])),max(np.abs(ImT11[chckind])))+0.05)\n",
    "    #plt.ylim(-1.05,1.05)\n",
    "    plt.plot(Horx, Hory,'red')\n",
    "    plt.plot(Thres1, ValatThres1,'red')\n",
    "    plt.plot(Thres2, ValatThres2,'red')\n",
    "    plt.plot(Thres3, ValatThres3,'red')\n",
    "    plt.plot(Thres4, ValatThres4,'red')\n",
    "    \n",
    "    plt.plot(Einput[chckind], ReT11[chckind],'+')\n",
    "    plt.plot(Einput[chckind], ImT11[chckind],'*')\n",
    "    plt.plot(Einput[chckind], ReT11[chckind]**2.0+ImT11[chckind]**2.0,'o')\n",
    "    plt.title('input data', fontsize=font_set_size)\n",
    "    plt.xlabel('$E_{cm}$ (MeV)', fontsize=font_set_size)\n",
    "    plt.xticks(fontsize=font_set_size)\n",
    "    plt.ylabel('$Re T_{11}$, $Im T_{11}$', fontsize=font_set_size)\n",
    "    plt.yticks(fontsize=font_set_size)\n",
    "    plt.tight_layout()\n",
    "    isactive = ['No', 'Yes']\n",
    "    \n",
    "    print('class','{:02d}'.format(labelout[chckind]),':',labelz[labelout[chckind]])\n",
    "    teburu = [\n",
    "    ['n','energy pole (MeV)', 'RS', 'Active','shadow1 (MeV)', 'RS1', 'shadow2 (MeV)', 'RS2'],\n",
    "    ['1','{:.2f}'.format(data_info[chckind][0][0]), data_info[chckind][1][0], isactive[data_info[chckind][3][0]], data_info[chckind][2][0][0], data_info[chckind][2][0][1], data_info[chckind][2][0][2], data_info[chckind][2][0][3]],\n",
    "    ['2','{:.2f}'.format(data_info[chckind][0][1]), data_info[chckind][1][1], isactive[data_info[chckind][3][1]], data_info[chckind][2][1][0], data_info[chckind][2][1][1], data_info[chckind][2][1][2], data_info[chckind][2][1][3]],\n",
    "    ['3','{:.2f}'.format(data_info[chckind][0][2]), data_info[chckind][1][2], isactive[data_info[chckind][3][2]], data_info[chckind][2][2][0], data_info[chckind][2][2][1], data_info[chckind][2][2][2], data_info[chckind][2][2][3]],\n",
    "    ['4','{:.2f}'.format(data_info[chckind][0][3]), data_info[chckind][1][3], isactive[data_info[chckind][3][3]], data_info[chckind][2][3][0], data_info[chckind][2][3][1], data_info[chckind][2][3][2], data_info[chckind][2][3][3]], \n",
    "    ['5','{:.2f}'.format(data_info[chckind][0][4]), data_info[chckind][1][4], isactive[data_info[chckind][3][4]], data_info[chckind][2][4][0], data_info[chckind][2][4][1], data_info[chckind][2][4][2], data_info[chckind][2][4][3]],\n",
    "    ['6','{:.2f}'.format(data_info[chckind][0][5]), data_info[chckind][1][5], isactive[data_info[chckind][3][5]], data_info[chckind][2][5][0], data_info[chckind][2][5][1], data_info[chckind][2][5][2], data_info[chckind][2][5][3]]\n",
    "    ]\n",
    "    \n",
    "    print(tabulate(teburu))\n",
    "    return plt.show(), chckind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportdata(Einput, ReT11, ImT11, labelout, data_info, directoryint):\n",
    "    #specify directory of files to be exported\n",
    "    #use test_Xpoles or train_Xpoles in directory name\n",
    "    out = directoryint\n",
    "    if not os.path.isdir(out):\n",
    "        os.makedirs(out)\n",
    "    #EXPORT generated data\n",
    "    pickle.dump (Einput, open(os.path.join(out,'Einput.pkl'),'wb'), protocol=4)\n",
    "    pickle.dump (ReT11, open(os.path.join(out,'ReT11.pkl'),'wb'), protocol=4)\n",
    "    pickle.dump (ImT11, open(os.path.join(out,'ImT11.pkl'),'wb'), protocol=4)\n",
    "    pickle.dump (labelout, open(os.path.join(out,'labelout.pkl'),'wb'), protocol=4)\n",
    "    pickle.dump (data_info, open(os.path.join(out,'data_info.pkl'),'wb'), protocol=4)\n",
    "    \n",
    "    #The following will collect the data that will go to the input layer:\n",
    "    #You can design a DNN with Einput and T11sqr in the input layer\n",
    "    T11sqr = [x**2.0 + y**2.0 for x, y in zip(ReT11, ImT11)]\n",
    "    T11sqr = np.concatenate((Einput,T11sqr), axis=1)\n",
    "    #or you can design a DNN with Einput, ReT11 and ImT11 in the input layer\n",
    "    T11 = np.concatenate((Einput,ReT11, ImT11), axis=1)\n",
    "    pickle.dump (T11sqr, open(os.path.join(out,'T11sqr.pkl'),'wb'), protocol=4)\n",
    "    pickle.dump (T11, open(os.path.join(out,'T11.pkl'),'wb'), protocol=4)\n",
    "    print('export done')        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importdata(directoryint):\n",
    "    #import dataset for inspection\n",
    "    out = directoryint\n",
    "    Einput = pickle.load(open(os.path.join(out,'Einput.pkl'),'rb'))\n",
    "    ReT11 = pickle.load(open(os.path.join(out,'ReT11.pkl'),'rb'))\n",
    "    ImT11 = pickle.load(open(os.path.join(out,'ImT11.pkl'),'rb'))\n",
    "    labelout = pickle.load(open(os.path.join(out,'labelout.pkl'),'rb'))\n",
    "    data_info= pickle.load(open(os.path.join(out,'data_info.pkl'),'rb'))\n",
    "    return Einput, ReT11, ImT11, labelout, data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traintest(Nshuffle, directory):\n",
    "    #If Nshuffle=0, it is understood that the testing dataset is to be prepared.\n",
    "    #Otherwise, it is the training dataset and Nshuffle determines shuffling times.\n",
    "    out = directory\n",
    "    #import prepared dataset\n",
    "    #inputtraining = pickle.load(open('T11sqr.pkl','rb')) #Use this if you want the amplitude square as input\n",
    "    inputtraining = pickle.load(open(os.path.join(out,'T11.pkl'),'rb')) #Use this if you want the real and imaginary part of amplitude as input\n",
    "    outputtraining = pickle.load(open(os.path.join(out,'labelout.pkl'),'rb'))\n",
    "    #we may need to convert to float32\n",
    "    inputtraining = np.float32(np.asarray(inputtraining))\n",
    "    print('size of dataset:', len(inputtraining))\n",
    "    print('number of nodes in input layer:',len(inputtraining[0]))\n",
    "    #shuffle the imported data\n",
    "    if Nshuffle != 0:\n",
    "        for ndx in range(Nshuffle):\n",
    "            inputtraining, outputtraining = shuffle(inputtraining, outputtraining)\n",
    "        #create input-output tuples that can be read by chainer\n",
    "        train = chainer.datasets.TupleDataset(inputtraining, outputtraining)\n",
    "        #split training set with testing set\n",
    "        pickle.dump (train, open(os.path.join(out,'chainer_train.pkl'),'wb'), protocol=4)\n",
    "    elif Nshuffle == 0:\n",
    "        #create input-output tuples that can be read by chainer\n",
    "        test = chainer.datasets.TupleDataset(inputtraining, outputtraining)\n",
    "        #split training set with testing set\n",
    "        pickle.dump (test, open(os.path.join(out,'chainer_test.pkl'),'wb'), protocol=4)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

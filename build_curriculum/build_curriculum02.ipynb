{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from module_poleclass.ipynb\n",
      "Number of poles to be generated per class: 3062500\n",
      "Ndata to be generated= 15312500\n",
      "Your directory is: curriculum02_training\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cmath as cm\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import chainer\n",
    "from chainer import configuration\n",
    "from chainer.dataset import convert\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from tabulate import tabulate\n",
    "\n",
    "import import_ipynb\n",
    "\n",
    "import module_poleclass\n",
    "from module_poleclass import mu1, mu2, T1, T2, T3, T4, Nreal, Nimag\n",
    "from module_poleclass import Ereal, Eimag, Erealfar, Eimagfar, E_exp, labelz\n",
    "from module_poleclass import pole, seerealimagpart, skipduplicate, exportdata, importdata, get_traintest, directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the old curriculum arrangement\n",
    "oldcurr = [0, 1, 11, 21,\n",
    "           2, 12, 22, 10, 20, 30,\n",
    "           3, 13, 23, 6, 8, 16, 18, 26, 28, 34,\n",
    "           4, 14, 24, 5, 7, 9, 15, 17, 19, 25, 27, 29, 31, 32, 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from gen_dataset00.ipynb\n",
      "importing Jupyter notebook from gen_dataset11.ipynb\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e20183f0e9cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_dataset00\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#import gen_dataset01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgen_dataset11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#import gen_dataset21\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\import_ipynb.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;31m# run the code in themodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\JUPYTER\\ex_JUPYTER\\dataset_maxedout\\gen_dataset11.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\JUPYTER\\ex_JUPYTER\\dataset_maxedout\\gen_dataset11.ipynb\u001b[0m in \u001b[0;36mgen_ccdataset11\u001b[1;34m(Ereal, Eimag, Erealfar, Eimagfar)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#generate curriculum02 dataset only\n",
    "import gen_dataset00\n",
    "#import gen_dataset01\n",
    "import gen_dataset11\n",
    "#import gen_dataset21\n",
    "\n",
    "import gen_dataset02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curriculum = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate curriculum02\n",
    "#Note: we used Nreal = 1800 and Nimag = 1800, giving us 5*(1800*1800)=16,200,000 data points\n",
    "Einput = pickle.load(open(os.path.join(directory,'Einput00.pkl'),'rb'))\n",
    "for add_data in range(1,curriculum+3):\n",
    "    xx = oldcurr[add_data]\n",
    "    EinputXX = pickle.load(open(os.path.join(directory,'Einput{:02d}.pkl'.format(xx)),'rb'))\n",
    "    Einput = Einput + EinputXX\n",
    "    del EinputXX\n",
    "    pickle.dump (Einput, open(os.path.join(directory,'Einput_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del Einput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReT11 = pickle.load(open(os.path.join(directory,'ReT1100.pkl'),'rb'))\n",
    "for add_data in range(1,curriculum+3):\n",
    "    xx = oldcurr[add_data]\n",
    "    ReT11XX = pickle.load(open(os.path.join(directory,'ReT11{:02d}.pkl'.format(xx)),'rb'))\n",
    "    ReT11 = ReT11 + ReT11XX\n",
    "    del ReT11XX\n",
    "    pickle.dump (ReT11, open(os.path.join(directory,'ReT11_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del ReT11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImT11 = pickle.load(open(os.path.join(directory,'ImT1100.pkl'),'rb'))\n",
    "for add_data in range(1,curriculum+3):\n",
    "    xx = oldcurr[add_data]\n",
    "    ImT11XX = pickle.load(open(os.path.join(directory,'ImT11{:02d}.pkl'.format(xx)),'rb'))\n",
    "    ImT11 = ImT11 + ImT11XX\n",
    "    del ImT11XX\n",
    "    pickle.dump (ImT11, open(os.path.join(directory,'ImT11_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del ImT11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelout = pickle.load(open(os.path.join(directory,'labelout00.pkl'),'rb'))\n",
    "for add_data in range(1,curriculum+3):\n",
    "    xx = oldcurr[add_data]\n",
    "    labeloutXX = pickle.load(open(os.path.join(directory,'labelout{:02d}.pkl'.format(xx)),'rb'))\n",
    "    labelout = labelout + labeloutXX\n",
    "    del labeloutXX\n",
    "    pickle.dump (labelout, open(os.path.join(directory,'labelout_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del labelout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T11 = np.concatenate((pickle.load(open(os.path.join(directory,'Einput_curr{:02d}.pkl'.format(curriculum)),'rb')),\n",
    "                      pickle.load(open(os.path.join(directory,'ReT11_curr{:02d}.pkl'.format(curriculum)),'rb'))\n",
    "                     ), axis=1)\n",
    "pickle.dump (T11, open(os.path.join(directory,'T11_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del T11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T11 = np.concatenate((pickle.load(open(os.path.join(directory,'T11_curr{:02d}.pkl'.format(curriculum)),'rb')),\n",
    "                      pickle.load(open(os.path.join(directory,'ImT11_curr{:02d}.pkl'.format(curriculum)),'rb'))\n",
    "                     ), axis=1)\n",
    "pickle.dump (T11, open(os.path.join(directory,'T11_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del T11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = directory\n",
    "Nshuffle = 400\n",
    "inputtraining = pickle.load(open(os.path.join(out,'T11_curr{:02d}.pkl'.format(curriculum)),'rb'))\n",
    "inputtraining = np.float32(np.asarray(inputtraining))\n",
    "outputtraining = pickle.load(open(os.path.join(out,'labelout_curr{:02d}.pkl'.format(curriculum)),'rb'))\n",
    "print('size of dataset:', len(inputtraining))\n",
    "print('number of nodes in input layer:',len(inputtraining[0]))    \n",
    "print(Nshuffle)\n",
    "for ndx in range(Nshuffle):\n",
    "    inputtraining, outputtraining = shuffle(inputtraining, outputtraining)\n",
    "print('Shuffling done')\n",
    "\n",
    "inputtraining = chainer.datasets.TupleDataset(inputtraining, outputtraining)\n",
    "del outputtraining\n",
    "print('done training set')\n",
    "pickle.dump (inputtraining, open(os.path.join(out,'chainer_train_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del inputtraining\n",
    "print('curriculum',1,'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
